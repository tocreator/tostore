# Tostore

[English](../../README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-CN.md) | [Êó•Êú¨Ë™û](README.ja.md) | [ÌïúÍµ≠Ïñ¥](README.ko.md) | [Espa√±ol](README.es.md) | [Portugu√™s (Brasil)](README.pt-BR.md) | [–†—É—Å—Å–∫–∏–π](README.ru.md) | Deutsch | [Fran√ßais](README.fr.md) | [Italiano](README.it.md) | [T√ºrk√ße](README.tr.md)

[![pub package](https://img.shields.io/pub/v/tostore.svg)](https://pub.dev/packages/tostore)
[![Build Status](https://github.com/tocreator/tostore/workflows/build/badge.svg)](https://github.com/tocreator/tostore/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Platform](https://img.shields.io/badge/Platform-Flutter-02569B?logo=flutter)](https://flutter.dev)
[![Dart Version](https://img.shields.io/badge/Dart-3.5+-00B4AB.svg?logo=dart)](https://dart.dev)

Tostore ist eine plattform√ºbergreifende Datenbank-Engine mit verteilter Architektur, die tief in Ihr Projekt integriert ist. Das von neuronalen Netzwerken inspirierte Datenverarbeitungsmodell implementiert eine gehirn√§hnliche Datenverarbeitung. Mehrfachpartitions-Parallelisierungsmechanismen und die Topologie miteinander verbundener Knoten schaffen ein intelligentes Datennetzwerk, w√§hrend die parallele Verarbeitung mit Isolates die F√§higkeiten von Mehrkernprozessoren voll ausnutzt. Mit verschiedenen Algorithmen f√ºr verteilte Prim√§rschl√ºssel und unbegrenzter Knotenerweiterung kann es als Datenschicht f√ºr verteilte Recheninfrastrukturen und gro√üangelegtes Datentraining dienen und erm√∂glicht einen nahtlosen Datenfluss von Edge-Ger√§ten bis zu Cloud-Servern. Funktionen wie die pr√§zise Erkennung von Schema√§nderungen, intelligente Migration, ChaCha20Poly1305-Verschl√ºsselung und eine Multi-Space-Architektur unterst√ºtzen perfekt verschiedene Anwendungsszenarien, von mobilen Apps bis hin zu serverseitigen Systemen.

## Warum Tostore w√§hlen?

### 1. Partitionsparallelit√§t vs. Einzeldateispeicherung
| Tostore | Traditionelle Datenbanken |
|:---------|:-----------|
| ‚úÖ Intelligenter Partitionierungsmechanismus, Daten verteilt auf mehrere Dateien angemessener Gr√∂√üe | ‚ùå Speicherung in einer einzigen Datendatei, lineare Leistungsverschlechterung mit wachsenden Daten |
| ‚úÖ Liest nur relevante Partitionsdateien, Abfrageleistung ist entkoppelt vom Gesamtdatenvolumen | ‚ùå Muss die gesamte Datendatei laden, selbst f√ºr die Abfrage eines einzelnen Datensatzes |
| ‚úÖ Beh√§lt Antwortzeiten im Millisekundenbereich auch bei TB-Datenmengen bei | ‚ùå Signifikante Erh√∂hung der Lese-/Schreiblatenz auf mobilen Ger√§ten, wenn Daten 5MB √ºberschreiten |
| ‚úÖ Ressourcenverbrauch proportional zur Menge der abgefragten Daten, nicht zum Gesamtdatenvolumen | ‚ùå Ressourcenbeschr√§nkte Ger√§te anf√§llig f√ºr Speicherdruck und OOM-Fehler |
| ‚úÖ Isolate-Technologie erm√∂glicht echte Mehrkern-Parallelverarbeitung | ‚ùå Eine einzelne Datei kann nicht parallel verarbeitet werden, Verschwendung von CPU-Ressourcen |

### 2. Dart-Parallelit√§t vs. traditionelle Skriptsprachen
| Tostore | Traditionelle skriptbasierte Datenbanken |
|:---------|:-----------|
| ‚úÖ Isolates f√ºhren echte Parallelausf√ºhrung ohne globale Sperrbeschr√§nkungen aus | ‚ùå Sprachen wie Python werden durch GIL eingeschr√§nkt, ineffizient f√ºr CPU-intensive Aufgaben |
| ‚úÖ AOT-Kompilierung erzeugt effizienten Maschinencode, nahezu native Leistung | ‚ùå Leistungsverlust bei der Datenverarbeitung durch interpretierte Ausf√ºhrung |
| ‚úÖ Unabh√§ngiges Speicher-Heap-Modell, vermeidet Lock- und Speicherkonflikte | ‚ùå Shared-Memory-Modell erfordert komplexe Sperrmechanismen bei hoher Nebenl√§ufigkeit |
| ‚úÖ Typsicherheit bietet Leistungsoptimierungen und Fehlerpr√ºfung zur Kompilierungszeit | ‚ùå Dynamische Typisierung entdeckt Fehler zur Laufzeit mit weniger Optimierungsm√∂glichkeiten |
| ‚úÖ Tiefe Integration mit dem Flutter-√ñkosystem | ‚ùå Erfordert zus√§tzliche ORM-Schichten und UI-Adapter, erh√∂ht die Komplexit√§t |

### 3. Eingebettete Integration vs. unabh√§ngige Datenspeicher
| Tostore | Traditionelle Datenbanken |
|:---------|:-----------|
| ‚úÖ Verwendet Dart-Sprache, nahtlose Integration mit Flutter/Dart-Projekten | ‚ùå Erfordert das Erlernen von SQL oder spezifischen Abfragesprachen, erh√∂ht die Lernkurve |
| ‚úÖ Derselbe Code unterst√ºtzt Frontend und Backend, kein Technologie-Stack-Wechsel n√∂tig | ‚ùå Frontend und Backend ben√∂tigen typischerweise unterschiedliche Datenbanken und Zugriffsmethoden |
| ‚úÖ Verkettete API-Stile passen zu modernen Programmierstilen, hervorragende Entwicklererfahrung | ‚ùå SQL-String-Verkettung ist anf√§llig f√ºr Angriffe und Fehler, mangelnde Typsicherheit |
| ‚úÖ Unterst√ºtzung f√ºr reaktive Programmierung, nat√ºrliche Verbindung mit UI-Frameworks | ‚ùå Erfordert zus√§tzliche Adaptionsschichten zur Verbindung von UI und Datenschicht |
| ‚úÖ Keine komplexe ORM-Mapping-Konfiguration erforderlich, direkte Verwendung von Dart-Objekten | ‚ùå Komplexit√§t des objekt-relationalen Mappings, hohe Entwicklungs- und Wartungskosten |

### 4. Pr√§zise Schema√§nderungserkennung vs. manuelle Migrationsverwaltung
| Tostore | Traditionelle Datenbanken |
|:---------|:-----------|
| ‚úÖ Erkennt Schema√§nderungen automatisch, keine Versionsnummernverwaltung erforderlich | ‚ùå Abh√§ngigkeit von manueller Versionskontrolle und explizitem Migrationscode |
| ‚úÖ Millisekunden-Erkennung von Tabellen-/Feld√§nderungen und automatische Datenmigration | ‚ùå Muss Migrationslogik f√ºr Upgrades zwischen Versionen pflegen |
| ‚úÖ Erkennt Tabellen-/Feldumbenennungen pr√§zise, beh√§lt alle historischen Daten bei | ‚ùå Tabellen-/Feldumbenennungen k√∂nnen zu Datenverlust f√ºhren |
| ‚úÖ Atomare Migrationsoperationen gew√§hrleisten Datenkonsistenz | ‚ùå Migrationsunterbrechungen k√∂nnen zu Dateninkonsistenzen f√ºhren |
| ‚úÖ Vollautomatisierte Schemaaktualisierungen ohne manuelle Eingriffe | ‚ùå Komplexe Upgrade-Logik und hohe Wartungskosten mit zunehmender Versionszahl |







## Technische Highlights

- üåê **Nahtlose plattform√ºbergreifende Unterst√ºtzung**:
  - Konsistente Erfahrung √ºber Web, Linux, Windows, Mobile, Mac Plattformen
  - Einheitliche API-Schnittstelle, problemlose plattform√ºbergreifende Datensynchronisation
  - Automatische Anpassung an verschiedene plattform√ºbergreifende Speicher-Backends (IndexedDB, Dateisysteme usw.)
  - Nahtloser Datenfluss von Edge-Computing bis zur Cloud

- üß† **Neuronale Netzwerk-inspirierte verteilte Architektur**:
  - Neuronale netzwerk√§hnliche Topologie miteinander verbundener Knoten
  - Effizienter Datenpartitionierungsmechanismus f√ºr verteilte Verarbeitung
  - Intelligente dynamische Workload-Balancierung
  - Unterst√ºtzung f√ºr unbegrenzte Knotenerweiterung, einfacher Aufbau komplexer Datennetzwerke

- ‚ö° **Ultimative Parallelverarbeitungsf√§higkeiten**:
  - Echt paralleles Lesen/Schreiben mit Isolates, volle CPU-Mehrkernnutzung
  - Mehrknoten-Rechennetzwerk arbeitet kooperativ, Multitasking-Effizienz multipliziert
  - Ressourcenbewusstes verteiltes Verarbeitungs-Framework, automatische Leistungsoptimierung
  - Streaming-Abfrageschnittstelle optimiert f√ºr die Verarbeitung gro√üer Datens√§tze

- üîë **Vielf√§ltige verteilte Prim√§rschl√ºsselalgorithmen**:
  - Sequentieller Inkrementalgorithmus - frei einstellbare zuf√§llige Schrittl√§nge
  - Zeitstempelbasierter Algorithmus - ideal f√ºr Hochleistungs-Parallelausf√ºhrungsszenarien
  - Datenpr√§fix-Algorithmus - geeignet f√ºr Daten mit Zeitbereichsindikation
  - Kurzcode-Algorithmus - pr√§gnante eindeutige Kennungen

- üîÑ **Intelligente Schemamigration**:
  - Pr√§zise Identifikation von Tabellen-/Feldumbenennungsverhalten
  - Automatische Aktualisierung und Datenmigration bei Schema√§nderungen
  - Zero-Downtime-Upgrades, keine Auswirkungen auf Gesch√§ftsoperationen
  - Sichere Migrationsstrategien, die Datenverlust verhindern

- üõ°Ô∏è **Unternehmenssicherheit**:
  - ChaCha20Poly1305-Verschl√ºsselungsalgorithmus zum Schutz sensibler Daten
  - Ende-zu-Ende-Verschl√ºsselung, Sicherheit gespeicherter und √ºbertragener Daten gew√§hrleistet
  - Feingranulare Datenzugriffskontrolle

- üöÄ **Intelligentes Caching und Suchleistung**:
  - Mehrstufiger intelligenter Caching-Mechanismus f√ºr effiziente Datenabfrage
  - Startup-Caching verbessert App-Startgeschwindigkeit dramatisch
  - Speicher-Engine tief mit Cache integriert, kein zus√§tzlicher Synchronisierungscode erforderlich
  - Adaptive Skalierung, stabile Leistung auch bei wachsenden Daten

- üîÑ **Innovative Workflows**:
  - Multi-Space-Datenisolierung, perfekte Unterst√ºtzung f√ºr Multi-Tenant-, Multi-User-Szenarien
  - Intelligente Workload-Zuweisung zwischen Rechenknoten
  - Robuste Datengrundlage f√ºr gro√üangelegtes Datentraining und -analyse
  - Automatische Datenspeicherung, intelligente Updates und Einf√ºgungen

- üíº **Entwicklererfahrung hat Priorit√§t**:
  - Detaillierte zweisprachige Dokumentation und Codekommentare (Chinesisch und Englisch)
  - Umfangreiche Debug-Informationen und Leistungsmetriken
  - Integrierte Datenvalidierung und Korruptionswiederherstellungsfunktionen
  - Zero-Konfiguration Out-of-the-Box, schneller Einstieg

## Schnellstart

Grundlegende Verwendung:

```dart
// Datenbank initialisieren
final db = ToStore();
await db.initialize(); // Optional, stellt sicher, dass die Datenbankinitialisierung abgeschlossen ist, bevor Operationen ausgef√ºhrt werden

// Daten einf√ºgen
await db.insert('users', {
  'username': 'John',
  'email': 'john@example.com',
});

// Daten aktualisieren
await db.update('users', {
  'age': 31,
}).where('id', '=', 1);

// Daten l√∂schen
await db.delete('users').where('id', '!=', 1);

// Unterst√ºtzung f√ºr komplexe verkettete Abfragen
final users = await db.query('users')
    .where('age', '>', 20)
    .where('name', 'like', '%John%')
    .or()
    .whereIn('id', [1, 2, 3])
    .orderByDesc('age')
    .limit(10);

// Automatische Datenspeicherung, aktualisiert wenn vorhanden, f√ºgt ein wenn nicht
await db.upsert('users', {'name': 'John','email': 'john@example.com'})
  .where('email', '=', 'john@example.com');
// Oder
await db.upsert('users', {
  'id': 1,
  'name': 'John',
  'email': 'john@example.com'
});

// Effiziente Datensatzz√§hlung
final count = await db.query('users').count();

// Verarbeitung gro√üer Datenmengen mit Streaming-Abfragen
db.streamQuery('users')
  .where('email', 'like', '%@example.com')
  .listen((userData) {
    // Verarbeite jeden Datensatz nach Bedarf, vermeidet Speicherdruck
    print('Verarbeite Benutzer: ${userData['username']}');
  });

// Globale Schl√ºssel-Wert-Paare setzen
await db.setValue('isAgreementPrivacy', true, isGlobal: true);

// Globale Schl√ºssel-Wert-Paar-Daten abrufen
final isAgreementPrivacy = await db.getValue('isAgreementPrivacy', isGlobal: true);
```

## Mobile App-Beispiel

```dart
// Tabellendefinition f√ºr h√§ufig startende Szenarien wie mobile Apps, pr√§zise Erkennung von Tabellenstruktur√§nderungen, automatisches Upgrade und Datenmigration
final db = ToStore(
  schemas: [
    const TableSchema(
      name: 'users', // Tabellenname
      tableId: "users",  // Eindeutige Tabellenkennung, optional, f√ºr 100% Erkennungsrate bei Umbenennungen, auch ohne kann >98% Genauigkeit erreicht werden
      primaryKeyConfig: PrimaryKeyConfig(
        name: 'id', // Prim√§rschl√ºssel
      ),
      fields: [ // Felddefinitionen, ohne Prim√§rschl√ºssel
        FieldSchema(name: 'username', type: DataType.text, nullable: false, unique: true),
        FieldSchema(name: 'email', type: DataType.text, nullable: false, unique: true),
        FieldSchema(name: 'last_login', type: DataType.datetime),
      ],
      indexes: [ // Indexdefinitionen
        IndexSchema(fields: ['username']),
        IndexSchema(fields: ['email']),
      ],
    ),
  ],
);

// Umschalten auf Benutzerraum - Datenisolierung
await db.switchSpace(spaceName: 'user_123');
```

## Backend-Server-Beispiel

```dart
await db.createTables([
      const TableSchema(
        name: 'users', // Tabellenname
        primaryKeyConfig: PrimaryKeyConfig(
          name: 'id', // Prim√§rschl√ºssel
          type: PrimaryKeyType.timestampBased,  // Prim√§rschl√ºsseltyp
        ),
        fields: [
          // Felddefinitionen, ohne Prim√§rschl√ºssel
          FieldSchema(
              name: 'username',
              type: DataType.text,
              nullable: false,
              unique: true),
          FieldSchema(name: 'vector_data', type: DataType.blob),  // Vektordaten speichern
          // Weitere Felder ...
        ],
        indexes: [
          // Indexdefinitionen
          IndexSchema(fields: ['username']),
          IndexSchema(fields: ['email']),
        ],
      ),
      // Weitere Tabellen ...
]);


// Tabellenstruktur aktualisieren
final taskId = await db.updateSchema('users')
    .renameTable('newTableName')  // Tabellenname √§ndern
    .modifyField('username',minLength: 5,maxLength: 20,unique: true)  // Feldeigenschaften √§ndern
    .renameField('oldName', 'newName')  // Feldname √§ndern
    .removeField('fieldName')  // Feld entfernen
    .addField('name', type: DataType.text)  // Feld hinzuf√ºgen
    .removeIndex(fields: ['age'])  // Index entfernen
    .setPrimaryKeyConfig(  // Prim√§rschl√ºsselkonfiguration setzen
      const PrimaryKeyConfig(type: PrimaryKeyType.shortCode)
    );
    
// Migrationsstatus abfragen
final status = await db.queryMigrationTaskStatus(taskId);  
print('Migrationsfortschritt: ${status?.progressPercentage}%');
```


## Verteilte Architektur

```dart
// Verteilte Knoten konfigurieren
final db = ToStore(
    config: DataStoreConfig(
        distributedNodeConfig: const DistributedNodeConfig(
            clusterId: 1,  // Clusterzugeh√∂rigkeit konfigurieren
            centralServerUrl: 'http://127.0.0.1:8080',
            accessToken: 'b7628a4f9b4d269b98649129'))
);

// Stapelweises Einf√ºgen von Vektordaten
await db.batchInsert('vector', [
  {'vector_name': 'face_2365', 'timestamp': DateTime.now()},
  {'vector_name': 'face_2366', 'timestamp': DateTime.now()},
  // ... Tausende von Datens√§tzen
]);

// Streaming-Verarbeitung gro√üer Datens√§tze f√ºr Analysen
await for (final record in db.streamQuery('vector')
    .where('vector_name', '=', 'face_2366')
    .where('timestamp', '>=', DateTime.now().subtract(Duration(days: 30)))
    .stream) {
  // Streaming-Schnittstelle unterst√ºtzt gro√üangelegte Merkmalextraktion und -transformation
  print(record);
}
```

## Prim√§rschl√ºsselbeispiele
Verschiedene Prim√§rschl√ºsselalgorithmen, alle unterst√ºtzen verteilte Generierung, eigene Prim√§rschl√ºsselgenerierung wird nicht empfohlen, um negative Auswirkungen ungeordneter Prim√§rschl√ºssel auf die Suchf√§higkeit zu vermeiden.
Sequentieller Prim√§rschl√ºssel PrimaryKeyType.sequential: 238978991
Zeitstempelbasierter Prim√§rschl√ºssel PrimaryKeyType.timestampBased: 1306866018836946
Datenpr√§fix-Prim√§rschl√ºssel PrimaryKeyType.datePrefixed: 20250530182215887631
Kurzcode-Prim√§rschl√ºssel PrimaryKeyType.shortCode: 9eXrF0qeXZ

```dart
// Sequentieller Prim√§rschl√ºssel PrimaryKeyType.sequential
// Bei aktivierter verteilter Nutzung weist der zentrale Server Bereiche zu, die Knoten selbst√§ndig generieren, kompakt und leicht zu merken, geeignet f√ºr Benutzer-IDs und sch√∂ne Nummern
await db.createTables([
      const TableSchema(
        name: 'users',
        primaryKeyConfig: PrimaryKeyConfig(
          type: PrimaryKeyType.sequential,  // Sequentieller Prim√§rschl√ºsseltyp
          sequentialConfig:  SequentialIdConfig(
              initialValue: 10000, // Startwert f√ºr Autoinkrement
              increment: 50,  // Inkrementschritt
              useRandomIncrement: true,  // Zuf√§llige Schrittl√§nge verwenden, um Gesch√§ftsvolumen zu verbergen
            ),
        ),
        // Feld- und Indexdefinitionen ...
        fields: []
      ),
      // Weitere Tabellen ...
 ]);
```


## Sicherheitskonfiguration

```dart
// Tabellen und Felder umbenennen - automatische Erkennung und Datenbeibehaltung
final db = ToStore(
      config: DataStoreConfig(
        enableEncoding: true, // Sichere Codierung f√ºr Tabellendaten aktivieren
        encodingKey: 'YouEncodingKey', // Codierungsschl√ºssel, kann beliebig angepasst werden
        encryptionKey: 'YouEncryptionKey', // Verschl√ºsselungsschl√ºssel, Hinweis: √Ñnderung verhindert Decodierung alter Daten
      ),
    );
```

## Leistungstests

Tostore 2.0 implementiert lineare Skalierbarkeit, grundlegende √Ñnderungen in Parallelverarbeitung, Partitionierungsmechanismen und verteilter Architektur haben die Datenabfragef√§higkeiten erheblich verbessert und erm√∂glichen millisekunden-schnelle Antwortzeiten selbst bei massivem Datenwachstum. F√ºr die Verarbeitung gro√üer Datens√§tze kann die Streaming-Abfrageschnittstelle massive Datenmengen verarbeiten, ohne Speicherressourcen zu ersch√∂pfen.



## Zukunftspl√§ne
Tostore entwickelt Unterst√ºtzung f√ºr hochdimensionale Vektoren, um multimodale Datenverarbeitung und semantische Suche zu erm√∂glichen.


Unser Ziel ist nicht, eine Datenbank zu erstellen; Tostore ist lediglich eine Komponente, die aus dem Toway-Framework f√ºr Ihre Betrachtung extrahiert wurde. Wenn Sie mobile Anwendungen entwickeln, empfehlen wir die Verwendung des Toway-Frameworks mit seinem integrierten √ñkosystem, das eine Full-Stack-L√∂sung f√ºr Flutter-Anwendungsentwicklung bietet. Mit Toway m√ºssen Sie nicht direkt mit der Datenbank interagieren, alle Operationen f√ºr Abfrage, Laden, Speichern, Caching und Anzeigen von Daten werden automatisch vom Framework √ºbernommen.
Weitere Informationen zum Toway-Framework finden Sie im [Toway-Repository](https://github.com/tocreator/toway).

## Dokumentation

Besuchen Sie unser [Wiki](https://github.com/tocreator/tostore) f√ºr detaillierte Dokumentation.

## Support und Feedback

- Issues einreichen: [GitHub Issues](https://github.com/tocreator/tostore/issues)
- An Diskussionen teilnehmen: [GitHub Discussions](https://github.com/tocreator/tostore/discussions)
- Code beitragen: [Contributing Guide](CONTRIBUTING.md)

## Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe [LICENSE](LICENSE) Datei f√ºr Details.

---

<p align="center">Wenn Sie Tostore hilfreich finden, geben Sie uns bitte einen ‚≠êÔ∏è</p>
